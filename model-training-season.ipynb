{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac92280e-c591-4534-a38b-b5f25235d173",
   "metadata": {},
   "source": [
    "## Regression model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612229c2-ffc2-4c3b-a033-c508e9cd7cd7",
   "metadata": {},
   "source": [
    "* open the sample of training points created in the preprocessing notebook\n",
    "* sample the predictors and the LST (10 m) at those locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d380ae7-62af-46c7-bb29-2ae634004948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterstats import point_query\n",
    "from shapely.geometry import mapping\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn import ensemble\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import sys\n",
    "from rasterio.crs import CRS\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c2206",
   "metadata": {},
   "source": [
    "#### Option 1: manual image selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 5000\n",
    "\n",
    "# date_s2 = '2023-06-25' #Summer\n",
    "# season = \"Summer\"\n",
    "\n",
    "# date_s2 = '2023-03-22' #Winter\n",
    "# season = \"Winter\"\n",
    "\n",
    "date_s2 = '2023-11-17' #Intermediate\n",
    "season = \"Intermediate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607cc3c",
   "metadata": {},
   "source": [
    "#### Option 2: Tagged cell as parameters and selection of a random parameters that will be rewriten by and extarnal file\n",
    "use this method if you intend to run with more than a single date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8f467",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# The following parameters are just and example and will be rewritten by driver.py\n",
    "date_s2 = '2023-11-17' #Intermediate\n",
    "season = \"Intermediate\"\n",
    "total_samples = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88445bc-44b2-4d60-bfd8-49b8e4352a7f",
   "metadata": {},
   "source": [
    "### Sample predictors and LST at the point locations and save the values in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1492fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path pattern for seasonal GeoPackages\n",
    "file_pattern = f\"/{season}_sampled_points_*_{total_samples}_all_bands.gpkg\"\n",
    "\n",
    "# Find all matching files\n",
    "file_list = glob.glob(file_pattern)\n",
    "\n",
    "# Load and combine all GeoPackages\n",
    "gdf_list = []\n",
    "for file in file_list:\n",
    "    print(f\"Loading: {file}\")\n",
    "    gdf = gpd.read_file(file)\n",
    "    \n",
    "    # Optional: Add date as a new column (parsed from filename)\n",
    "    date_str = os.path.basename(file).split('_')[3]  # Extract yyyymmdd\n",
    "    gdf[\"date\"] = pd.to_datetime(date_str, format='%Y%m%d')\n",
    "    \n",
    "    gdf_list.append(gdf)\n",
    "\n",
    "# Concatenate into one GeoDataFrame\n",
    "df_full = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True), crs=gdf_list[0].crs)\n",
    "\n",
    "print(f\"\\nTotal stacked samples: {len(df_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52c7325f-29c7-401f-b290-9cf179287ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = df_full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007f2bf-be61-4f84-8e5b-4cc65f3c8a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c038b-770e-4867-8749-2fcff00d951b",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "* split the points into training and testing samples\n",
    "* perform cross-validation for hyperparameter tuning\n",
    "* after the selection of the best parameters, evaluate the model error (RMSE, MAE) and coefficient of determination (R2)\n",
    "* use the model to predict LST in all pixels of the AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466417be-35a4-4ac8-9752-a1914441bbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_X = df_full.drop(columns=[\"LCZ\", \"LST\", \"geometry\", \"date\"])\n",
    "print(df_X)\n",
    "series_y = df_full.iloc[:, 1]\n",
    "print(series_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc61d08-126e-446f-b089-0237d5cd1881",
   "metadata": {},
   "source": [
    "### 1. Split the points into training and testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86d504df-1420-4c0a-8906-d805c753a900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, series_y, train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab00c9-2c8b-40fa-8616-2ba425e1e9da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print dataset sizes\n",
    "print(f\"Train size: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test size: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db84d485-b729-47a0-b66c-bbd11fcc59df",
   "metadata": {},
   "source": [
    "### 2. K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e2e87926-b8e2-47d1-9c49-442d34cafed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200],\n",
    "    'max_depth': [5, 10, 20, 30, 50],\n",
    "    'max_features': [1.0, 'sqrt'],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01d6a2-d270-427e-8166-64c1da2c127b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select best hyperparameters\n",
    "scoring_metric = 'neg_mean_squared_error'\n",
    "#scoring_metric = 'r2'\n",
    "grid_search = GridSearchCV(ensemble.RandomForestRegressor(), param_grid, scoring = scoring_metric, cv = 5, verbose = 1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best hyperparameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126a08f-dd62-4227-b330-049b596e2c29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the negative mean test scores\n",
    "scores = -grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(np.sqrt(scores), bins=30, color='orange', edgecolor='black', alpha=0.75)\n",
    "\n",
    "# Update layout\n",
    "plt.title(f'Distribution of Cross-Validation Scores for Season: {season}')\n",
    "plt.xlabel('Average RMSE (°K) in the folds')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(False)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe725cd-59b5-4dbb-a96b-d4918c984f3c",
   "metadata": {},
   "source": [
    "### 3. Build the model and evaluate it on the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200147d6-7d4b-4744-a5dd-d3a556ee9270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regr = ensemble.RandomForestRegressor(n_estimators = best_params['n_estimators'],\n",
    "                                     max_depth = best_params['max_depth'],\n",
    "                                     max_features = best_params['max_features'],\n",
    "                                     min_samples_split = best_params['min_samples_split'],\n",
    "                                     min_samples_leaf = best_params['min_samples_leaf'])\n",
    "\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b60ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create output directory with model name\n",
    "model_folder = f\"/saved_model_{season}_{total_samples}_samples\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save best_params\n",
    "with open(os.path.join(model_folder, \"best_params.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(best_params, f)\n",
    "\n",
    "# Save trained model\n",
    "with open(os.path.join(model_folder, \"regr_model.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(regr, f)\n",
    "\n",
    "# Save sampled data (df_full)\n",
    "df_full.to_csv(os.path.join(model_folder, \"sampled_data.csv\"), index=False)\n",
    "\n",
    "print(f\"Saved model and parameters to: {model_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4708297d-3059-465d-9af0-d435f93c761b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_test = regr.predict(X_test)\n",
    "y_pred_train = regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c3723-0d5c-4a28-83c7-5cc890c60cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"MAE on TRAINING: \", round(mae, 3))\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "print(\"MAE on TESTING: \", round(mae, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cba912-4cbc-46f8-9ad5-6d36aaab58d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(y_train, y_pred_train)\n",
    "rmse = math.sqrt(rmse)\n",
    "print(\"RMSE on TRAINING: \", round(rmse, 3))\n",
    "rmse = mean_squared_error(y_test, y_pred_test)\n",
    "rmse = math.sqrt(rmse)\n",
    "print(\"RMSE on TESTING: \", round(rmse, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a16832-0418-4614-9df4-cc5593a12c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2 = r2_score(y_train, y_pred_train)\n",
    "print(\"R2 on TRAINING: \", round(r2, 3))\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"R2 on TESTING: \", round(r2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Bias Error (MBE)\n",
    "mbe_train = np.mean(y_pred_train - y_train)\n",
    "mbe_test = np.mean(y_pred_test - y_test)\n",
    "\n",
    "print(\"MBE on TRAINING: \", round(mbe_train, 3))\n",
    "print(\"MBE on TESTING: \", round(mbe_test, 3))\n",
    "\n",
    "# Mean Absolute Bias (same as MAE, already computed earlier)\n",
    "mab_train = np.mean(np.abs(y_pred_train - y_train))\n",
    "mab_test = np.mean(np.abs(y_pred_test - y_test))\n",
    "\n",
    "print(\"MAB on TRAINING: \", round(mab_train, 3))\n",
    "print(\"MAB on TESTING: \", round(mab_test, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8998270-3459-40ac-a071-48d3cb85ab7c",
   "metadata": {},
   "source": [
    "### 4. Evaluate feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1ed493e-7024-4a42-95ce-45307673c9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importances = regr.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d5fa4-92da-49c3-9b23-802213c6eb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the bar chart\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.barh(\n",
    "    importance_df['Feature'],\n",
    "    importance_df['Importance'],\n",
    "    color='skyblue',\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title(f'Feature Importances for Season: {season}')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "\n",
    "# Tight layout and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9af2c-bf7c-44af-aa38-d790878b7c49",
   "metadata": {},
   "source": [
    "### 5. Stack the predictors and put them in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49139774",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_l8 = f\"Average_LST_map_{season}.tif\"\n",
    "# === Step 2: List of raster files to sample ===\n",
    "rasters = {\n",
    "    'LST': '\\Input\\LST_L89\\Mediated_LST/' + file_l8[:-4] + '_10m.tif',\n",
    "    'BH': '\\UCP/UCP_20m/BH_10m.tif',\n",
    "    'BSF': '\\UCP/UCP_20m/BSF_10m.tif',\n",
    "    'IMD': '\\UCP/UCP_20m/IMD_10m.tif',\n",
    "    'SVF': '\\UCP/UCP_20m/SVF_10m.tif',\n",
    "    'TCH': '\\UCP/UCP_20m/TCH_10m.tif',\n",
    "    'Fractions': ('Fractions/Final_Class_Fraction_Layer_Masked_' + date_s2 + '_10m.tif', \n",
    "                 ['F_S', 'F_M', 'F_AC', 'F_BS', 'F_TV', 'F_W', 'F_G'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e14ec16a-3313-4761-8b3b-74579fa7fe85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "reference_shape = None\n",
    "\n",
    "# Helper function to validate shape\n",
    "def check_shape(shape, name):\n",
    "    global reference_shape\n",
    "    if reference_shape is None:\n",
    "        reference_shape = shape\n",
    "    elif shape != reference_shape:\n",
    "        raise ValueError(f\"Shape mismatch for {name}: {shape} != {reference_shape}\")\n",
    "\n",
    "# Process rasters\n",
    "for key, value in rasters.items():\n",
    "    if key != 'Fractions':\n",
    "        with rasterio.open(value) as src:\n",
    "            arr = src.read(1)\n",
    "            predictor_meta = src.meta\n",
    "            check_shape(arr.shape, key)\n",
    "            data[key] = arr.flatten()\n",
    "    else:\n",
    "        path, band_names = value\n",
    "        with rasterio.open(path) as src:\n",
    "            for i, band_name in enumerate(band_names, start=1):\n",
    "                arr = src.read(i)\n",
    "                check_shape(arr.shape, band_name)\n",
    "                data['Fractions_' + band_name] = arr.flatten()\n",
    "\n",
    "# Stack into DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3289a-d85a-4c43-8d18-92d828c59ab9",
   "metadata": {},
   "source": [
    "### 6. Predict on all the pixels and export the prediction to TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e0f4b-924a-4256-9761-5c220226d0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = regr.predict(df.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8ba13-d574-4679-868d-c24a9bec6b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2bbc6-cdba-4d1b-b457-cbc501c496da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_reshaped = prediction.reshape(reference_shape[0], reference_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792903c-f564-4b8f-bebb-eb46e11d9133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_meta = predictor_meta.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ab5c9-02ad-4268-8778-3984a0f3d7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with rasterio.open('\\LST_L89/model_predictions/predicted_LST_' + date_s2.replace('-', '') + '_20m_' + str(total_samples) + '_samples.tif', 'w', **output_meta) as dst:\n",
    "    dst.write(prediction_reshaped, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ef4cf-f45f-4873-9e70-4cebca7bcc0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(prediction_reshaped, cmap='Spectral_r')\n",
    "#plt.title(f'Predicted Temperature for Date: {date_s2}')\n",
    "plt.title(f'Predicted Temperature')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d37c456-8619-41b6-b011-a4fdeb2b86a8",
   "metadata": {},
   "source": [
    "### 7. Compute R<sup>2</sup>, RMSE, MAE and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed32147-9d74-47e2-bba0-3204c7e1bd93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# Combine all values to find global min and max\n",
    "all_values = np.concatenate([y_train, y_pred_train, y_test, y_pred_test])\n",
    "min_val = np.min(all_values)\n",
    "max_val = np.max(all_values)\n",
    "\n",
    "# Optional: pad the range slightly for visual clarity\n",
    "padding = 2  # degrees K\n",
    "min_val -= padding\n",
    "max_val += padding\n",
    "# Reference line: y = x (perfect prediction)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[min_val, max_val],\n",
    "    y=[min_val, max_val],\n",
    "    mode='lines',\n",
    "    line=dict(color='grey'),\n",
    "    name='y = x'\n",
    "))\n",
    "\n",
    "# Scatter plot for training data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_train,\n",
    "    y=y_pred_train,\n",
    "    mode='markers',\n",
    "    marker=dict(color='blue', opacity=0.5),\n",
    "    name='Train'\n",
    "))\n",
    "\n",
    "# Scatter plot for test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test,\n",
    "    y=y_pred_test,\n",
    "    mode='markers',\n",
    "    marker=dict(color='red', opacity=0.5),\n",
    "    name='Test'\n",
    "))\n",
    "\n",
    "# Combine all values to find global min and max\n",
    "all_values = np.concatenate([y_train, y_pred_train, y_test, y_pred_test])\n",
    "min_val = np.min(all_values) - 2\n",
    "max_val = np.max(all_values) + 2\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=f'Scatter Plot for Season: {season}',\n",
    "    xaxis=dict(\n",
    "        title='Regression Prediction (°K)',\n",
    "        range=[min_val, max_val]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='True Value (°K)',\n",
    "        range=[min_val, max_val],\n",
    "        scaleanchor='x',\n",
    "        scaleratio=1\n",
    "    ),\n",
    "    width=600,\n",
    "    height=600,\n",
    "    showlegend=True,\n",
    "    template='simple_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018c6b5-9d8d-4bcc-8029-5ab685714936",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 8. Compute residuals (both for train and test) and export to Geopackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Compute residuals\n",
    "residuals_train = y_train - y_pred_train\n",
    "residuals_test = y_test - y_pred_test\n",
    "\n",
    "# Add predictions and residuals back into the original DataFrame\n",
    "train_df = X_train.copy()\n",
    "train_df[\"Observed\"] = y_train\n",
    "train_df[\"Predicted\"] = y_pred_train\n",
    "train_df[\"Residual\"] = residuals_train\n",
    "train_df[\"Split\"] = \"train\"\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df[\"Observed\"] = y_test\n",
    "test_df[\"Predicted\"] = y_pred_test\n",
    "test_df[\"Residual\"] = residuals_test\n",
    "test_df[\"Split\"] = \"test\"\n",
    "\n",
    "# Combine train and test\n",
    "combined_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add index to align later\n",
    "gdf = gdf.reset_index(drop=True)\n",
    "\n",
    "# Ensure index is aligned with df_X\n",
    "df_X = df_X.reset_index(drop=True)\n",
    "\n",
    "# Join residual info to geometry\n",
    "df_with_geometry = pd.concat([df_X, gdf[[\"geometry\"]]], axis=1)\n",
    "\n",
    "# Now join predictions & residuals back to spatial points\n",
    "final_df = df_with_geometry.merge(combined_df[[\"Observed\", \"Predicted\", \"Residual\", \"Split\"]], \n",
    "                                  left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to GeoDataFrame\n",
    "final_gdf = gpd.GeoDataFrame(final_df, geometry=\"geometry\", crs=gdf.crs)\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "output_path = f\"/model_predictions/residuals_{date_s2.replace('-', '')}.gpkg\"\n",
    "final_gdf.to_file(output_path, layer=\"residuals\", driver=\"GPKG\")\n",
    "\n",
    "print(f\"Residuals exported to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823453e7-969f-4bfe-967b-13462e63f328",
   "metadata": {},
   "source": [
    "### 9. Compute the residuals on ALL pixels and export them as a TIF (map of differences between actual LST and predicted LST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec5ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Prepare your data.\n",
    "crs = final_gdf.crs\n",
    "\n",
    "# Base raster reference parameters (adjust these values to your actual base raster)\n",
    "pixel_size = 10  # Example pixel size (adjust according to your dataset)\n",
    "minx, miny, maxx, maxy = final_gdf.total_bounds\n",
    "width = int((maxx - minx) / pixel_size)\n",
    "height = int((maxy - miny) / pixel_size)\n",
    "transform = rasterio.transform.from_origin(minx, maxy, pixel_size, pixel_size)\n",
    "\n",
    "# Step 2: Prepare data for rasterization (geometry, value pairs)\n",
    "shapes = ((geom, value) for geom, value in zip(final_gdf.geometry, final_gdf.Residual))\n",
    "\n",
    "# Step 3: Rasterize the residuals\n",
    "residual_raster = rasterize(\n",
    "    shapes,\n",
    "    out_shape=(height, width),\n",
    "    fill=np.nan,  # No data value\n",
    "    transform=transform,\n",
    "    dtype='float32',\n",
    ")\n",
    "\n",
    "# Step 4: Export the raster to GeoTIFF\n",
    "output_tif_path = f'/residuals_20m_' + str(total_samples) + '_samples.tif'\n",
    "\n",
    "with rasterio.open(\n",
    "    output_tif_path,\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=residual_raster.shape[0],\n",
    "    width=residual_raster.shape[1],\n",
    "    count=1,\n",
    "    dtype=residual_raster.dtype,\n",
    "    crs=crs,\n",
    "    transform=transform,\n",
    "    nodata=np.nan\n",
    ") as dst:\n",
    "    dst.write(residual_raster, 1)\n",
    "\n",
    "print(f\"Residuals raster exported to {output_tif_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7eed98",
   "metadata": {},
   "source": [
    "# Apply Model on Data with changed UCPs and Fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "786d65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.warp import reproject, Resampling, calculate_default_transform\n",
    "from rasterio.enums import Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d6ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_file_path = os.path.join('\\LST_L89\\Mediated_LST/', file_l8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BH_file_path = '\\simulated_covariates/BH_pct.tif'\n",
    "BSF_file_path = '\\simulated_covariates/BSF_pct.tif'\n",
    "IMD_file_path = '\\simulated_covariates/IMD_pct.tif'\n",
    "SVF_file_path = '\\simulated_covariates/SVF_pct.tif'\n",
    "TCH_file_path = '\\simulated_covariates/TCH_pct.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2814892",
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = '\\Final_Class_Fraction_Layer_Masked_' + date_s2 + '.tif'\n",
    "fractions = '\\simulated_covariates/Simulated_Fraction_1.tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8bf169f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_predictors = [\n",
    "    lst_file_path,\n",
    "    BH_file_path,\n",
    "    BSF_file_path,\n",
    "    IMD_file_path,\n",
    "    SVF_file_path,\n",
    "    TCH_file_path,\n",
    "    fractions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3552b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_path in input_predictors:\n",
    "    \n",
    "    output_path = input_path[:-4] + '_10m.tif'\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        with rasterio.open(input_path) as src:\n",
    "            src_crs = src.crs or CRS.from_epsg(32632)\n",
    "            dst_resolution = 10\n",
    "\n",
    "            transform, width, height = calculate_default_transform(\n",
    "                src_crs, src_crs, src.width, src.height, *src.bounds, resolution=dst_resolution\n",
    "            )\n",
    "\n",
    "            kwargs = src.meta.copy()\n",
    "            kwargs.update({\n",
    "                'transform': transform,\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'res': (dst_resolution, dst_resolution),\n",
    "                'compress': 'lzw'\n",
    "            })\n",
    "\n",
    "            with rasterio.open(output_path, 'w', **kwargs) as dst:\n",
    "                \n",
    "                for i in range(1, src.count + 1):\n",
    "                    reproject(\n",
    "                        source=rasterio.band(src, i),\n",
    "                        destination=rasterio.band(dst, i),\n",
    "                        src_transform=src.transform,\n",
    "                        src_crs=src.crs,\n",
    "                        dst_transform=transform,\n",
    "                        dst_crs=src.crs,\n",
    "                        resampling=Resampling.nearest\n",
    "                    )\n",
    "        print(f\"Processed: {output_path}\")\n",
    "    else:\n",
    "        print(f\"Skipped (already exists): {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3de295cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = fractions[:-4] + '_10m.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "780f20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_rasters = [\n",
    "    BH_file_path[:-4] + '_10m.tif',\n",
    "    BSF_file_path[:-4] + '_10m.tif',\n",
    "    IMD_file_path[:-4] + '_10m.tif',\n",
    "    SVF_file_path[:-4] + '_10m.tif',\n",
    "    TCH_file_path[:-4] + '_10m.tif',\n",
    "    lst_file_path[:-4] + '_10m.tif'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663af20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(reference) as ref:\n",
    "    ref_crs = ref.crs or CRS.from_epsg(32632)\n",
    "    ref_transform = ref.transform\n",
    "    ref_width = ref.width\n",
    "    ref_height = ref.height\n",
    "\n",
    "for raster_path in input_rasters:\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        profile = src.profile\n",
    "        profile.update({\n",
    "            'crs': ref_crs,\n",
    "            'transform': ref_transform,\n",
    "            'width': ref_width,\n",
    "            'height': ref_height\n",
    "        })\n",
    "\n",
    "        # Create an empty array to store the aligned data\n",
    "        aligned = np.empty((ref_height, ref_width), dtype=src.dtypes[0])\n",
    "\n",
    "        # Reproject and resample from source to aligned array\n",
    "        reproject(\n",
    "            source=src.read(1),  # Read band 1\n",
    "            destination=aligned,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=ref_transform,\n",
    "            dst_crs=ref_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "\n",
    "    # Overwrite the original file with the aligned version\n",
    "    with rasterio.open(raster_path, 'w', **profile) as dst:\n",
    "        dst.write(aligned, 1)\n",
    "\n",
    "    print(f'Aligned and overwritten: {raster_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa88289-8105-4f1a-a903-56d334c27b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_l8 = f\"Average_LST_map_{season}.tif\"\n",
    "# === Step 2: List of raster files to sample ===\n",
    "rasters_pct = {\n",
    "    'LST': '\\Input\\LST_L89\\Mediated_LST/' + file_l8[:-4] + '_10m.tif',\n",
    "    'BH': '\\simulated_covariates/BH_pct_10m.tif',\n",
    "    'BSF': '\\simulated_covariates/BSF_pct_10m.tif',\n",
    "    'IMD': '\\simulated_covariates/IMD_pct_10m.tif',\n",
    "    'SVF': '\\simulated_covariates/SVF_pct_10m.tif',\n",
    "    'TCH': '\\simulated_covariates/TCH_pct_10m.tif',\n",
    "    'Fractions': ('simulated_covariates\\Simulated_Fraction_1_10m.tif', \n",
    "                 ['F_S', 'F_M', 'F_AC', 'F_BS', 'F_TV', 'F_W', 'F_G'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "09477fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "reference_shape = None\n",
    "\n",
    "# Helper function to validate shape\n",
    "def check_shape(shape, name):\n",
    "    global reference_shape\n",
    "    if reference_shape is None:\n",
    "        reference_shape = shape\n",
    "    elif shape != reference_shape:\n",
    "        raise ValueError(f\"Shape mismatch for {name}: {shape} != {reference_shape}\")\n",
    "\n",
    "# Process rasters\n",
    "for key, value in rasters_pct.items():\n",
    "    if key != 'Fractions':\n",
    "        with rasterio.open(value) as src:\n",
    "            arr = src.read(1)\n",
    "            predictor_meta = src.meta\n",
    "            check_shape(arr.shape, key)\n",
    "            data[key] = arr.flatten()\n",
    "    else:\n",
    "        path, band_names = value\n",
    "        with rasterio.open(path) as src:\n",
    "            for i, band_name in enumerate(band_names, start=1):\n",
    "                arr = src.read(i)\n",
    "                check_shape(arr.shape, band_name)\n",
    "                data['Fractions_' + band_name] = arr.flatten()\n",
    "\n",
    "# Stack into DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "38098ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = regr.predict(df.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f63b0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_reshaped = prediction.reshape(reference_shape[0], reference_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c6084",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_meta = predictor_meta.copy()\n",
    "with rasterio.open('/simulated_covariates_predicted_LST_' + date_s2.replace('-', '') + '_20m_' + str(total_samples) + '_samples.tif', 'w', **output_meta) as dst:\n",
    "    dst.write(prediction_reshaped, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2defbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(prediction_reshaped, cmap='Spectral_r')\n",
    "plt.title(f'Predicted Temperature')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Reference line: y = x (perfect prediction)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_train,\n",
    "    y=y_train,\n",
    "    mode='lines',\n",
    "    line=dict(color='grey'),\n",
    "    name='y = x'\n",
    "))\n",
    "\n",
    "# Scatter plot for training data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_train,\n",
    "    y=y_pred_train,\n",
    "    mode='markers',\n",
    "    marker=dict(color='blue', opacity=0.5),\n",
    "    name='Train'\n",
    "))\n",
    "\n",
    "# Scatter plot for test data\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test,\n",
    "    y=y_pred_test,\n",
    "    mode='markers',\n",
    "    marker=dict(color='red', opacity=0.5),\n",
    "    name='Test'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Scatter Plot for Season: {season}',\n",
    "    xaxis_title='Regression Prediction (°K)',\n",
    "    yaxis_title='True Value (°K)',\n",
    "    width=600,\n",
    "    height=600,\n",
    "    showlegend=True,\n",
    "    template='simple_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
